"""
Factory para inicializa√ß√£o de LLM com fallback para ambiente local.

Este m√≥dulo implementa a l√≥gica de fallback que verifica primeiro
se h√° credenciais do Azure OpenAI dispon√≠veis. Caso n√£o existam,
utiliza automaticamente o LLM da OpenAI padr√£o via LangChain.
"""

import os
import logging
from typing import Optional
from dotenv import load_dotenv

# Carregar vari√°veis de ambiente do arquivo .env
load_dotenv()

try:
    from langchain_openai import ChatOpenAI, AzureChatOpenAI
    from langchain_core.language_models.chat_models import BaseChatModel
except ImportError:
    raise ImportError(
        "LangChain OpenAI n√£o est√° instalado. Execute: pip install langchain-openai"
    )


class LLMInitializationError(Exception):
    """Exce√ß√£o levantada quando n√£o √© poss√≠vel inicializar nenhum provedor LLM."""
    pass


class LLMFactory:
    """
    Factory respons√°vel pela cria√ß√£o de inst√¢ncias LLM com fallback autom√°tico.
    
    Implementa a l√≥gica de verifica√ß√£o de credenciais e inicializa√ß√£o
    do provedor adequado (Azure OpenAI ou OpenAI padr√£o).

    Atualizado para incluir gera√ß√£o de hist√≥rias com detalhes e justificativas.
    """
    
    def __init__(self):
        """Inicializa o factory com logger configurado."""
        self.logger = logging.getLogger(__name__)
    
    def _check_azure_credentials(self) -> bool:
        """
        Verifica se todas as credenciais necess√°rias do Azure OpenAI est√£o presentes.
        
        Returns:
            bool: True se todas as credenciais est√£o dispon√≠veis, False caso contr√°rio
        """
        required_vars = [
            "AZURE_OPENAI_API_KEY",
            "AZURE_OPENAI_API_BASE", 
            "AZURE_OPENAI_DEPLOYMENT_NAME",
            "AZURE_OPENAI_API_VERSION"
        ]
        
        missing_vars = []
        for var in required_vars:
            if not os.getenv(var):
                missing_vars.append(var)
        
        if missing_vars:
            self.logger.info(
                f"Credenciais do Azure OpenAI ausentes: {', '.join(missing_vars)}. "
                "Tentando fallback para OpenAI padr√£o."
            )
            return False
        
        return True
    
    def _check_openai_credentials(self) -> bool:
        """
        Verifica se as credenciais necess√°rias da OpenAI padr√£o est√£o presentes.
        
        Returns:
            bool: True se as credenciais est√£o dispon√≠veis, False caso contr√°rio
        """
        required_vars = ["OPENAI_API_KEY", "OPENAI_MODEL_NAME"]
        
        missing_vars = []
        for var in required_vars:
            if not os.getenv(var):
                missing_vars.append(var)
        
        if missing_vars:
            self.logger.error(
                f"Credenciais da OpenAI padr√£o ausentes: {', '.join(missing_vars)}."
            )
            return False
        
        return True
    
    def _create_azure_llm(self) -> AzureChatOpenAI:
        """
        Cria uma inst√¢ncia do Azure OpenAI LLM.
        
        Returns:
            AzureChatOpenAI: Inst√¢ncia configurada do Azure OpenAI
        """
        try:
            azure_llm = AzureChatOpenAI(
                api_key=os.getenv("AZURE_OPENAI_API_KEY"),
                azure_endpoint=os.getenv("AZURE_OPENAI_API_BASE"),
                deployment_name=os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME"),
                api_version=os.getenv("AZURE_OPENAI_API_VERSION"),
                temperature=0.7,
                max_tokens=15000,
                timeout=120,  # 2 minutos de timeout para chamadas LLM
                max_retries=3
            )
            
            self.logger.info(
                f"‚úÖ Azure OpenAI inicializado com sucesso - "
                f"Endpoint: {os.getenv('AZURE_OPENAI_API_BASE')} | "
                f"Deployment: {os.getenv('AZURE_OPENAI_DEPLOYMENT_NAME')}"
            )
            
            return azure_llm
            
        except Exception as e:
            self.logger.error(f"‚ùå Erro ao inicializar Azure OpenAI: {e}")
            raise LLMInitializationError(f"Falha na inicializa√ß√£o do Azure OpenAI: {e}")
    
    def _create_openai_llm(self) -> ChatOpenAI:
        """
        Cria uma inst√¢ncia do OpenAI padr√£o LLM.
        
        Returns:
            ChatOpenAI: Inst√¢ncia configurada da OpenAI padr√£o
        """
        try:
            openai_llm = ChatOpenAI(
                api_key=os.getenv("OPENAI_API_KEY"),
                model=os.getenv("OPENAI_MODEL_NAME", "gpt-4"),
                temperature=0.7,
                max_tokens=15000,
                timeout=120,  # 2 minutos de timeout para chamadas LLM
                max_retries=3
            )
            
            self.logger.info(
                f"‚úÖ OpenAI padr√£o inicializado com sucesso - "
                f"Modelo: {os.getenv('OPENAI_MODEL_NAME', 'gpt-4')}"
            )
            
            return openai_llm
            
        except Exception as e:
            self.logger.error(f"‚ùå Erro ao inicializar OpenAI padr√£o: {e}")
            raise LLMInitializationError(f"Falha na inicializa√ß√£o da OpenAI padr√£o: {e}")
    
    def load_llm(self) -> BaseChatModel:
        """
        Carrega uma inst√¢ncia de LLM com fallback autom√°tico.
        
        Verifica primeiro se as credenciais do Azure OpenAI est√£o dispon√≠veis.
        Caso n√£o estejam, tenta utilizar a OpenAI padr√£o.
        Se nenhuma estiver dispon√≠vel, levanta uma exce√ß√£o.
        
        Returns:
            BaseChatModel: Inst√¢ncia configurada do LLM (Azure ou OpenAI padr√£o)
            
        Raises:
            LLMInitializationError: Quando nenhum provedor pode ser inicializado
        """
        self.logger.info("üîÑ Iniciando processo de carregamento do LLM...")
        
        # Primeira tentativa: Azure OpenAI
        if self._check_azure_credentials():
            try:
                return self._create_azure_llm()
            except LLMInitializationError:
                self.logger.warning("‚ö†Ô∏è Falha no Azure OpenAI, tentando fallback...")
        
        # Segunda tentativa: OpenAI padr√£o
        if self._check_openai_credentials():
            try:
                return self._create_openai_llm()
            except LLMInitializationError:
                self.logger.error("‚ùå Falha tamb√©m na OpenAI padr√£o")
        
        # Nenhum provedor dispon√≠vel
        error_msg = (
            "‚ùå Nenhum provedor LLM pode ser inicializado. "
            "Verifique as vari√°veis de ambiente:\n"
            "Para Azure OpenAI: AZURE_OPENAI_API_KEY, AZURE_OPENAI_API_BASE, "
            "AZURE_OPENAI_DEPLOYMENT_NAME, AZURE_OPENAI_API_VERSION\n"
            "Para OpenAI padr√£o: OPENAI_API_KEY, OPENAI_MODEL_NAME"
        )
        
        self.logger.error(error_msg)
        raise LLMInitializationError(error_msg)


# Novos prompts integrados para StoryCreator
# O LLM agora deve gerar hist√≥rias mais detalhadas, incluindo explica√ß√µes para prioridade e estimativa.


# Inst√¢ncia global do factory
llm_factory = LLMFactory()


def load_llm() -> BaseChatModel:
    """
    Fun√ß√£o de conveni√™ncia para carregar o LLM.
    
    Returns:
        BaseChatModel: Inst√¢ncia configurada do LLM
        
    Raises:
        LLMInitializationError: Quando nenhum provedor pode ser inicializado
    """
    return llm_factory.load_llm()
